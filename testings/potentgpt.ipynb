{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def search_web(search_topic, location):\n",
    "    MY_ENV_VAR = os.getenv('SERP_API_AUTH')\n",
    "    api_key = MY_ENV_VAR\n",
    "    api_endpoint = 'https://serpapi.com/search'\n",
    "\n",
    "    params = {\n",
    "        'q': search_topic,\n",
    "        'location': location,\n",
    "        'api_key': api_key\n",
    "    }\n",
    "\n",
    "    response = requests.get(api_endpoint, params=params)\n",
    "    data = response.json()\n",
    "\n",
    "    websites = [result['link'] for result in data['organic_results']]\n",
    "    website_names = [result['title'] for result in data['organic_results']]\n",
    "\n",
    "    for website_name in website_names:\n",
    "        print(website_name)\n",
    "\n",
    "    return websites\n",
    "\n",
    "# # Example usage\n",
    "# search_web('best bagels in Seattle', 'Seattle, WA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hire the best React.js developers\n",
      "11 Best Freelance React.js Developers [Hire in 48 Hours]\n",
      "11 Best Freelance Full-Stack Developers [Hire in 48 Hours]\n",
      "Hire the best React Native developers\n",
      "Hire Python and React.js Developers\n",
      "Remote Python/React developer jobs\n",
      "Hire React Native Developers With Lemon.io\n",
      "Who wants to be hired (May 2023) Â· vercel next.js\n",
      "Developers that have started their own business : r/webdev\n",
      "I think I haven't made any progress even after investing ...\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# goal\n",
    "goal = \"I need few developers for my new startup, I am looking for people with 2 years of experience in python and react.\"\n",
    "location = \"Bengaluru, Karnataka, India\"\n",
    "\n",
    "# fetch the sites\n",
    "websites = search_web(goal, location)\n",
    "\n",
    "flag1 = time.time()\n",
    "print(\"Time taken to fetch the sites: \", flag1 - start_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.upwork.com/hire/react-js-developers/',\n",
       " 'https://www.toptal.com/react',\n",
       " 'https://www.toptal.com/full-stack',\n",
       " 'https://www.upwork.com/hire/react-native-developers/',\n",
       " 'https://www.voypost.com/hire-python-and-react-js-developers',\n",
       " 'https://www.turing.com/jobs/remote-python-react-developer',\n",
       " 'https://lemon.io/hire-react-native-developers/',\n",
       " 'https://github.com/vercel/next.js/discussions/49472',\n",
       " 'https://www.reddit.com/r/webdev/comments/12hz450/developers_that_have_started_their_own_business/',\n",
       " 'https://forum.freecodecamp.org/t/i-think-i-havent-made-any-progress-even-after-investing-the-time-give-some-advice/438513']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_html_junk(data):\n",
    "    # remove all class names\n",
    "    data = re.sub(r'(?is)class=\"[^\"]*\"', '', data)\n",
    "    data = re.sub(r'(?is)className=\"[^\"]*\"', '', data)\n",
    "\n",
    "    # remove all inline styles\n",
    "    data = re.sub(r'(?is)style=\"[^\"]*\"', '', data)\n",
    "\n",
    "    # remove all aria-label\n",
    "    data = re.sub(r'(?is)aria-label=\"[^\"]*\"', '', data)\n",
    "\n",
    "    # remove all comments\n",
    "    data = re.sub(r'(?s)<!--(.*?)-->[\\n]?', '', data)\n",
    "\n",
    "    # remove all ids\n",
    "    data = re.sub(r'(?is)id=\"[^\"]*\"', '', data)\n",
    "\n",
    "    # remove all newlines, long space and tabs\n",
    "    data = re.sub(r'[\\n\\t]', ' ', data)\n",
    "    data = re.sub(r' +', ' ', data)\n",
    "\n",
    "    # remove all non-imp tags both open and close\n",
    "    remove_tags = [\"span\", \"div\", \"strong\", \"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\"]   \n",
    "    for tag in remove_tags:\n",
    "        data = re.sub(r'(?is)<{}[^>]*>'.format(tag), '', data)\n",
    "        data = re.sub(r'(?is)</{}[^>]*>'.format(tag), '', data) \n",
    "\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xrange' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/anshuman/Anshu/Projects/PotentGPT/testings/potentgpt.ipynb Cell 6\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anshuman/Anshu/Projects/PotentGPT/testings/potentgpt.ipynb#W5sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anshuman/Anshu/Projects/PotentGPT/testings/potentgpt.ipynb#W5sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m website_url \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhttps://python.langchain.com/docs/use_cases/web_scraping\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/anshuman/Anshu/Projects/PotentGPT/testings/potentgpt.ipynb#W5sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m data \u001b[39m=\u001b[39m scrape_data(website_url)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anshuman/Anshu/Projects/PotentGPT/testings/potentgpt.ipynb#W5sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39mlen\u001b[39m(data)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anshuman/Anshu/Projects/PotentGPT/testings/potentgpt.ipynb#W5sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39mprint\u001b[39m(data)\n",
      "\u001b[1;32m/home/anshuman/Anshu/Projects/PotentGPT/testings/potentgpt.ipynb Cell 6\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anshuman/Anshu/Projects/PotentGPT/testings/potentgpt.ipynb#W5sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m         data \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39mbody\u001b[39m.\u001b[39mprettify()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anshuman/Anshu/Projects/PotentGPT/testings/potentgpt.ipynb#W5sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     \u001b[39m# data = remove_html_junk(soup.main.prettify())\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/anshuman/Anshu/Projects/PotentGPT/testings/potentgpt.ipynb#W5sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     data \u001b[39m=\u001b[39m h\u001b[39m.\u001b[39mhandle(data)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anshuman/Anshu/Projects/PotentGPT/testings/potentgpt.ipynb#W5sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m data\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anshuman/Anshu/Projects/PotentGPT/testings/potentgpt.ipynb#W5sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Anshu/Projects/PotentGPT/testings/html2text.py:243\u001b[0m, in \u001b[0;36mHTML2Text.handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhandle\u001b[39m(\u001b[39mself\u001b[39m, data):\n\u001b[0;32m--> 243\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeed(data)\n\u001b[1;32m    244\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeed(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    245\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptwrap(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose())\n",
      "File \u001b[0;32m~/Anshu/Projects/PotentGPT/testings/html2text.py:240\u001b[0m, in \u001b[0;36mHTML2Text.feed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeed\u001b[39m(\u001b[39mself\u001b[39m, data):\n\u001b[1;32m    239\u001b[0m     data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m</\u001b[39m\u001b[39m'\u001b[39m\u001b[39m + \u001b[39m\u001b[39m'\u001b[39m\u001b[39mscript>\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m</ignore>\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 240\u001b[0m     HTMLParser\u001b[39m.\u001b[39mHTMLParser\u001b[39m.\u001b[39mfeed(\u001b[39mself\u001b[39m, data)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm-env/lib/python3.11/html/parser.py:110\u001b[0m, in \u001b[0;36mHTMLParser.feed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Feed data to the parser.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[39mCall this as often as you want, with as little or as much text\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[39mas you want (may include '\\n').\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrawdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrawdata \u001b[39m+\u001b[39m data\n\u001b[0;32m--> 110\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgoahead(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm-env/lib/python3.11/html/parser.py:162\u001b[0m, in \u001b[0;36mHTMLParser.goahead\u001b[0;34m(self, end)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m<\u001b[39m j:\n\u001b[1;32m    161\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvert_charrefs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcdata_elem:\n\u001b[0;32m--> 162\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_data(unescape(rawdata[i:j]))\n\u001b[1;32m    163\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    164\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_data(rawdata[i:j])\n",
      "File \u001b[0;32m~/Anshu/Projects/PotentGPT/testings/html2text.py:668\u001b[0m, in \u001b[0;36mHTML2Text.handle_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcode \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpre:\n\u001b[1;32m    667\u001b[0m     data \u001b[39m=\u001b[39m escape_md_section(data, snob\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mescape_snob)\n\u001b[0;32m--> 668\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mo(data, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Anshu/Projects/PotentGPT/testings/html2text.py:598\u001b[0m, in \u001b[0;36mHTML2Text.o\u001b[0;34m(self, data, puredata, force)\u001b[0m\n\u001b[1;32m    596\u001b[0m     bq \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m    \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    597\u001b[0m \u001b[39m#else: list content is already partially indented\u001b[39;00m\n\u001b[0;32m--> 598\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m xrange(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlist)):\n\u001b[1;32m    599\u001b[0m     bq \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m    \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    600\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mbq)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xrange' is not defined"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import html2text\n",
    "\n",
    "h = html2text.HTML2Text()\n",
    "\n",
    "def scrape_data(url):\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        unwanted_tags = [\n",
    "            \"pre\",\n",
    "            \"code\",\n",
    "            \"blockquote\",\n",
    "            \"em\",\n",
    "            \"br\",\n",
    "            \"source\",\n",
    "            \"circle\",\n",
    "            \"svg\",\n",
    "            \"img\",\n",
    "            \"button\",\n",
    "            \"input\",\n",
    "            \"form\",\n",
    "            \"footer\",\n",
    "            \"header\",\n",
    "            \"aside\",\n",
    "            \"nav\",\n",
    "            \"script\",\n",
    "            \"style\",\n",
    "            \"noscript\",\n",
    "            \"iframe\",\n",
    "            \"meta\",\n",
    "            \"head\",\n",
    "        ]\n",
    "        # for tag in unwanted_tags:\n",
    "        #     for match in soup.find_all(tag):\n",
    "        #         match.decompose()\n",
    "        \n",
    "        try:\n",
    "            # data = soup.body.prettify()\n",
    "            data = soup.main.prettify()\n",
    "        except:\n",
    "            data = soup.body.prettify()\n",
    "\n",
    "        # data = remove_html_junk(soup.main.prettify())\n",
    "        data = h.handle(data)\n",
    "        return data\n",
    "\n",
    "    else:\n",
    "        print(\n",
    "            f\"Error: Unable to fetch data from {url}. Status code: {response.status_code}\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "\n",
    "website_url = \"https://python.langchain.com/docs/use_cases/web_scraping\"\n",
    "data = scrape_data(website_url)\n",
    "len(data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/anshuman/Anshu/Projects/PotentGPT/testings/potentgpt.ipynb Cell 7\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anshuman/Anshu/Projects/PotentGPT/testings/potentgpt.ipynb#W6sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m splits[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mpage_content\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anshuman/Anshu/Projects/PotentGPT/testings/potentgpt.ipynb#W6sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m urls \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mhttps://www.wsj.com\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/anshuman/Anshu/Projects/PotentGPT/testings/potentgpt.ipynb#W6sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m extracted_content \u001b[39m=\u001b[39m scrape_with_playwright(urls, schema\u001b[39m=\u001b[39mschema)\n",
      "\u001b[1;32m/home/anshuman/Anshu/Projects/PotentGPT/testings/potentgpt.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anshuman/Anshu/Projects/PotentGPT/testings/potentgpt.ipynb#W6sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscrape_with_playwright\u001b[39m(urls, schema):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anshuman/Anshu/Projects/PotentGPT/testings/potentgpt.ipynb#W6sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     loader \u001b[39m=\u001b[39m AsyncChromiumLoader(urls)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/anshuman/Anshu/Projects/PotentGPT/testings/potentgpt.ipynb#W6sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     docs \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39mload()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anshuman/Anshu/Projects/PotentGPT/testings/potentgpt.ipynb#W6sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     bs_transformer \u001b[39m=\u001b[39m beautiful_soup_transformer\u001b[39m.\u001b[39mBeautifulSoupTransformer()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anshuman/Anshu/Projects/PotentGPT/testings/potentgpt.ipynb#W6sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     docs_transformed \u001b[39m=\u001b[39m bs_transformer\u001b[39m.\u001b[39mtransform_documents(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anshuman/Anshu/Projects/PotentGPT/testings/potentgpt.ipynb#W6sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m         docs, tags_to_extract\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mspan\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anshuman/Anshu/Projects/PotentGPT/testings/potentgpt.ipynb#W6sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/llm-env/lib/python3.11/site-packages/langchain/document_loaders/chromium.py:90\u001b[0m, in \u001b[0;36mAsyncChromiumLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Document]:\n\u001b[1;32m     82\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[39m    Load and return all Documents from the provided URLs.\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     88\u001b[0m \n\u001b[1;32m     89\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlazy_load())\n",
      "File \u001b[0;32m~/miniconda3/envs/llm-env/lib/python3.11/site-packages/langchain/document_loaders/chromium.py:77\u001b[0m, in \u001b[0;36mAsyncChromiumLoader.lazy_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39mLazily load text content from the provided URLs.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     74\u001b[0m \n\u001b[1;32m     75\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[39mfor\u001b[39;00m url \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39murls:\n\u001b[0;32m---> 77\u001b[0m     html_content \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39mrun(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mascrape_playwright(url))\n\u001b[1;32m     78\u001b[0m     metadata \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39msource\u001b[39m\u001b[39m\"\u001b[39m: url}\n\u001b[1;32m     79\u001b[0m     \u001b[39myield\u001b[39;00m Document(page_content\u001b[39m=\u001b[39mhtml_content, metadata\u001b[39m=\u001b[39mmetadata)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm-env/lib/python3.11/asyncio/runners.py:186\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \n\u001b[1;32m    163\u001b[0m \u001b[39mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[39m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[39mif\u001b[39;00m events\u001b[39m.\u001b[39m_get_running_loop() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[39m# fail fast with short traceback\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    187\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    189\u001b[0m \u001b[39mwith\u001b[39;00m Runner(debug\u001b[39m=\u001b[39mdebug) \u001b[39mas\u001b[39;00m runner:\n\u001b[1;32m    190\u001b[0m     \u001b[39mreturn\u001b[39;00m runner\u001b[39m.\u001b[39mrun(main)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "from langchain.document_transformers import Html2TextTransformer, beautiful_soup_transformer\n",
    "from langchain.document_loaders import AsyncChromiumLoader\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.chains import create_extraction_chain\n",
    "\n",
    "schema = {\n",
    "    \"properties\": {\n",
    "        \"news_article_title\": {\"type\": \"string\"},\n",
    "        \"news_article_summary\": {\"type\": \"string\"},\n",
    "    },\n",
    "    \"required\": [\"news_article_title\", \"news_article_summary\"],\n",
    "}\n",
    "\n",
    "\n",
    "# def extract(content: str, schema: dict):\n",
    "#     return create_extraction_chain(schema=schema, llm=llm).run(content)\n",
    "\n",
    "\n",
    "def scrape_with_playwright(urls, schema):\n",
    "    loader = AsyncChromiumLoader(urls)\n",
    "    docs = loader.load()\n",
    "    bs_transformer = beautiful_soup_transformer.BeautifulSoupTransformer()\n",
    "    docs_transformed = bs_transformer.transform_documents(\n",
    "        docs, tags_to_extract=[\"span\"]\n",
    "    )\n",
    "    print(\"Extracting content with LLM\")\n",
    "\n",
    "    # Grab the first 1000 tokens of the site\n",
    "    splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=1000, chunk_overlap=0\n",
    "    )\n",
    "    splits = splitter.split_documents(docs_transformed)\n",
    "\n",
    "    # Process the first split\n",
    "    # extracted_content = extract(schema=schema, content=splits[0].page_content)\n",
    "    print(splits[0].page_content)\n",
    "    # pprint.pprint(extracted_content)\n",
    "    return splits[0].page_content\n",
    "\n",
    "\n",
    "urls = [\"https://www.wsj.com\"]\n",
    "extracted_content = scrape_with_playwright(urls, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html2text\n",
    "\n",
    "# Create an instance of the HTML2Text class\n",
    "h = html2text.HTML2Text()\n",
    "\n",
    "# Use the instance to convert HTML to text\n",
    "html_content = \"<p>Hello, World!</p>\"\n",
    "text_content = h.handle(html_content)\n",
    "\n",
    "print(text_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "MY_ENV_VAR = os.getenv('OPENAI_API_KEY')\n",
    "client = OpenAI(api_key=MY_ENV_VAR)\n",
    "print(\"client ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a helpful assistant, and your job is to get new ideas and information for your boss.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "EXAMPLE1 = \"I want to hire a chef for this weekend to make South Indian cuisine for 50 people.\"\n",
    "\n",
    "# EXAMPLE1_ANS = \"\"\"\n",
    "# Questions for the vendor or candidate:[\n",
    "# How many years of experience do you have as a chef?,\n",
    "# What is your hourly charge in rupees?,\n",
    "# Do you have expertise in specific cuisines or types of dishes? Will you be able to make South Indian cuisine?,\n",
    "# Are you comfortable with the dynamic work hours and cooking food for more than 50 people?,\n",
    "# How do you interact with customers to understand their preferences and ensure satisfaction?\n",
    "# ]\n",
    "# \"\"\"\n",
    "\n",
    "PROMPT = \"I need a flat in banglore for rent.\"\n",
    "PROMPT2 = \"I need few developers for my new startup, I am looking for people with 2 years of experience in python and react.\"\n",
    "\n",
    "begin = time.time() \n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  n=1,\n",
    "  model = \"gpt-3.5-turbo\",\n",
    "  temperature = 0.2,\n",
    "  max_tokens = 400,\n",
    "  messages = [\n",
    "    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "    {\"role\": \"user\", \"content\": EXAMPLE1},\n",
    "    {\"role\": \"assistant\", \"content\": EXAMPLE1_ANS},\n",
    "    {\"role\": \"user\", \"content\": PROMPT2}\n",
    "  ]\n",
    ")\n",
    "\n",
    "end = time.time() \n",
    "print(completion.choices[0].message.content)\n",
    "print(\"\\n\",(end - begin) , \" Seconds\")\n",
    "print(f'Total Tokens:{completion.usage.total_tokens}, Prompt Token {completion.usage.prompt_tokens}, Completion Token {completion.usage.completion_tokens}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb Cell 12\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X14sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39m# websites = {result['title']:result['link'] for result in data['organic_results']}\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X14sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m data\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X14sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m data \u001b[39m=\u001b[39m search_web_google(\u001b[39m\"\u001b[39m\u001b[39mI need few developers for my new startup, I am looking for people with 2 years of experience in python and react.\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mBengaluru, Karnataka, India\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X14sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mprint\u001b[39m(data[\u001b[39m'\u001b[39m\u001b[39mitems\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[1;32m/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X14sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msearch_web_google\u001b[39m(search_topic, location):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X14sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     GOOGLE_API_KEY \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mgetenv(\u001b[39m'\u001b[39m\u001b[39mGOOGLE_API_KEY\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X14sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     api_endpoint \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://www.googleapis.com/customsearch/v1?key=\u001b[39m\u001b[39m{\u001b[39;00mGOOGLE_API_KEY\u001b[39m}\u001b[39;00m\u001b[39m&cx=81ad9e204a3204be3\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X14sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     location \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mBengaluru, Karnataka, India\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.tools import Tool\n",
    "from langchain.utilities import GoogleSearchAPIWrapper\n",
    "\n",
    "# search = GoogleSearchAPIWrapper()\n",
    "\n",
    "# tool = Tool(\n",
    "#     name=\"Google Search\",\n",
    "#     description=\"Search Google for recent results.\",\n",
    "#     func=search.run,\n",
    "# )\n",
    "\n",
    "\n",
    "def search_web_google(search_topic, location):\n",
    "    GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "    api_endpoint = f'https://www.googleapis.com/customsearch/v1?key={GOOGLE_API_KEY}&cx=81ad9e204a3204be3'\n",
    "    location = \"Bengaluru, Karnataka, India\"\n",
    "    params = {\n",
    "        'q': search_topic,\n",
    "        'gl': location,\n",
    "        'lr': 'lang_en',\n",
    "        'num': 10\n",
    "    }\n",
    "    websites = {}\n",
    "\n",
    "    response = requests.get(api_endpoint, params=params)\n",
    "    data = response.json()\n",
    "\n",
    "    # websites = {result['title']:result['link'] for result in data['organic_results']}\n",
    "\n",
    "    return data\n",
    "\n",
    "data = search_web_google(\"I need few developers for my new startup, I am looking for people with 2 years of experience in python and react.\", \"Bengaluru, Karnataka, India\")\n",
    "print(data['items'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.json', 'w') as f:\n",
    "    json.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SERP Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "import logging as log\n",
    "from dotenv import load_dotenv\n",
    "from langchain.document_transformers import Html2TextTransformer, beautiful_soup_transformer\n",
    "\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging\n",
    "log.basicConfig(\n",
    "    format=\"%(levelname)s - %(message)s\", level=log.DEBUG\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def search_web(search_topic, location):\n",
    "    MY_ENV_VAR = os.getenv('SERP_API_AUTH')\n",
    "    api_key = MY_ENV_VAR\n",
    "    api_endpoint = 'https://serpapi.com/search'\n",
    "\n",
    "    params = {\n",
    "        'q': search_topic,\n",
    "        'location': location,\n",
    "        'api_key': api_key\n",
    "    }\n",
    "    websites = {}\n",
    "\n",
    "    response = requests.get(api_endpoint, params=params)\n",
    "    data = response.json()\n",
    "\n",
    "    websites = {result['title']:result['link'] for result in data['organic_results']}\n",
    "\n",
    "    return websites\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "root - INFO - Searching for \"I want to get a bus service for wedding family trip in Kerala\" in \"Kollam, Kerala, India\"\n",
      "urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): serpapi.com:443\n",
      "urllib3.connectionpool - DEBUG - https://serpapi.com:443 \"GET /search?q=I+want+to+get+a+bus+service+for+wedding+family+trip+in+Kerala&location=Kollam%2C+Kerala%2C+India&api_key=a52394bb80ac1ec136ccffe9fa402b8c2a4ec73827b57988e50bb0eeae3a37ac HTTP/1.1\" 200 None\n",
      "root - INFO - Found 10 websites\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anshuman/miniconda3/envs/llm-env/lib/python3.11/logging/__init__.py\", line 1110, in emit\n",
      "    msg = self.format(record)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anshuman/miniconda3/envs/llm-env/lib/python3.11/logging/__init__.py\", line 953, in format\n",
      "    return fmt.format(record)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anshuman/miniconda3/envs/llm-env/lib/python3.11/logging/__init__.py\", line 687, in format\n",
      "    record.message = record.getMessage()\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anshuman/miniconda3/envs/llm-env/lib/python3.11/logging/__init__.py\", line 377, in getMessage\n",
      "    msg = msg % self.args\n",
      "          ~~~~^~~~~~~~~~~\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/home/anshuman/miniconda3/envs/llm-env/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/anshuman/miniconda3/envs/llm-env/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/anshuman/miniconda3/envs/llm-env/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 736, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/anshuman/miniconda3/envs/llm-env/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/anshuman/miniconda3/envs/llm-env/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/anshuman/miniconda3/envs/llm-env/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/anshuman/miniconda3/envs/llm-env/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/anshuman/miniconda3/envs/llm-env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/anshuman/miniconda3/envs/llm-env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/anshuman/miniconda3/envs/llm-env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/anshuman/miniconda3/envs/llm-env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/anshuman/miniconda3/envs/llm-env/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/anshuman/miniconda3/envs/llm-env/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/anshuman/miniconda3/envs/llm-env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/anshuman/miniconda3/envs/llm-env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/home/anshuman/miniconda3/envs/llm-env/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/anshuman/miniconda3/envs/llm-env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/anshuman/miniconda3/envs/llm-env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/anshuman/miniconda3/envs/llm-env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_8408/1258650210.py\", line 14, in <module>\n",
      "    log.info(\"Time taken to fetch the sites: \", flag1 - start_time)\n",
      "Message: 'Time taken to fetch the sites: '\n",
      "Arguments: (7.424551248550415,)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# goal\n",
    "goal = \"I need few developers for my new startup, I am looking for people with 2 years of experience in python and react.\"\n",
    "search_prompt = \"I want to get a bus service for wedding family trip in Kerala\"\n",
    "location = \"Kollam, Kerala, India\"\n",
    "\n",
    "log.info(f'Searching for \"{search_prompt}\" in \"{location}\"')\n",
    "\n",
    "# fetch the sites\n",
    "websites = search_web(search_prompt, location)\n",
    "log.info(f'Found {len(websites)} websites')\n",
    "\n",
    "flag1 = time.time()\n",
    "log.info(\"Time taken to fetch the sites: \", flag1 - start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kerala tourist bus fare, tourist bus in cochin, tempo traveller ...': 'https://keralatourbus.com/',\n",
       " 'Top Bus On Rent For Wedding in Kerala, Thrissur': 'https://www.justdial.com/Thrissur/Bus-On-Rent-For-Wedding-in-Kerala/nct-11275471',\n",
       " 'Top Bus On Rent For Wedding in Ernakulam': 'https://www.justdial.com/Ernakulam/Bus-On-Rent-For-Wedding/nct-11275471',\n",
       " 'Wedding Bus| Bus Booking For Marriage On redBus.in': 'https://www.redbus.in/bus-hire/wedding',\n",
       " '35, 36, 40, 54, 55 seater Bus Rental in Kochi, Bus on Rent ...': 'https://www.sulekha.com/bus-rentals/cochin',\n",
       " 'Bus Rental in Trivandrum': 'https://www.sulekha.com/bus-rentals/trivandrum',\n",
       " 'Oneness Travels | Wedding Transportation in Kerala': 'https://www.shaadibaraati.com/wedding-transportation/kerala/oneness-travels/MGyvjmIxtV',\n",
       " 'Bus Rental in Cochin | 49,35 seater Bus Hire | TaxiCarKerala': 'https://devannmpd.wixsite.com/taxicarkerala/tourist-buses-in-cochin',\n",
       " 'Luxury Bus Hire In Cochin - Coach': 'https://www.asparkholidays.com/cochin/luxury-bus-hire',\n",
       " 'Book Volvo Bus In Trivandrum': 'https://www.asparkholidays.com/thiruvananthapuram/book-volvo-bus'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_junk(data):\n",
    "    # remove all class names\n",
    "    data = re.sub(r'(?is)class=\"[^\"]*\"', '', data)\n",
    "    data = re.sub(r'(?is)className=\"[^\"]*\"', '', data)\n",
    "\n",
    "    # remove all inline styles\n",
    "    data = re.sub(r'(?is)style=\"[^\"]*\"', '', data)\n",
    "\n",
    "    # remove all aria-label\n",
    "    data = re.sub(r'(?is)aria-label=\"[^\"]*\"', '', data)\n",
    "\n",
    "    # remove all comments\n",
    "    data = re.sub(r'(?s)<!--(.*?)-->[\\n]?', '', data)\n",
    "\n",
    "    # remove all ids\n",
    "    data = re.sub(r'(?is)id=\"[^\"]*\"', '', data)\n",
    "\n",
    "    # remove all newlines, long space and tabs\n",
    "    data = re.sub(r'[\\n\\t]', ' ', data)\n",
    "    data = re.sub(r' +', ' ', data)\n",
    "\n",
    "    # remove all non-imp tags both open and close\n",
    "    remove_tags = [\"span\", \"div\", \"strong\", \"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\", \"b\", \"li\", \"p\", \"ui\", \"section\"]   \n",
    "    for tag in remove_tags:\n",
    "        data = re.sub(r'(?is)<{}[^>]*>'.format(tag), '', data)\n",
    "        data = re.sub(r'(?is)</{}[^>]*>'.format(tag), '', data) \n",
    "\n",
    "    return data\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import html2text\n",
    "\n",
    "h = html2text.HTML2Text()\n",
    "\n",
    "def scrape_data(url):\n",
    "    log.info(f\"\\nScraping data from {url}\")\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        \n",
    "        unwanted_tags = [\n",
    "            \"pre\",\n",
    "            \"code\",\n",
    "            \"blockquote\",\n",
    "            \"em\",\n",
    "            \"br\",\n",
    "            \"source\",\n",
    "            \"circle\",\n",
    "            \"svg\",\n",
    "            \"img\",\n",
    "            \"button\",\n",
    "            \"input\",\n",
    "            \"form\",\n",
    "            \"footer\",\n",
    "            \"header\",\n",
    "            \"aside\",\n",
    "            \"nav\",\n",
    "            \"script\",\n",
    "            \"style\",\n",
    "            \"noscript\",\n",
    "            \"iframe\",\n",
    "            \"meta\",\n",
    "            \"head\",\n",
    "            \n",
    "        ]\n",
    "        for tag in unwanted_tags:\n",
    "            for match in soup.find_all(tag):\n",
    "                match.decompose()\n",
    "        if soup.body is None:\n",
    "            log.warning(f\"Error: Unable to fetch data from {url}\")\n",
    "            return \"\"\n",
    "        try:\n",
    "            # data = soup.body.prettify()\n",
    "            data = soup.main.prettify()\n",
    "        except:\n",
    "            data = soup.body.prettify()\n",
    "\n",
    "        data = remove_html_junk(data)\n",
    "\n",
    "    \n",
    "        log.info(f\"Successfully scraped data from {url}\")   \n",
    "        return data\n",
    "\n",
    "    else:\n",
    "        log.warning(\n",
    "            f\"Error: Unable to fetch data from {url}. Status code: {response.status_code}\"\n",
    "        )\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "root - INFO - \n",
      "Scraping data from https://keralatourbus.com/\n",
      "urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): keralatourbus.com:443\n",
      "urllib3.connectionpool - DEBUG - https://keralatourbus.com:443 \"GET / HTTP/1.1\" 403 None\n",
      "root - WARNING - Error: Unable to fetch data from https://keralatourbus.com/. Status code: 403\n",
      "root - INFO - \n",
      "Scraping data from https://www.justdial.com/Thrissur/Bus-On-Rent-For-Wedding-in-Kerala/nct-11275471\n",
      "urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.justdial.com:443\n",
      "urllib3.connectionpool - DEBUG - https://www.justdial.com:443 \"GET /Thrissur/Bus-On-Rent-For-Wedding-in-Kerala/nct-11275471 HTTP/1.1\" 403 356\n",
      "root - WARNING - Error: Unable to fetch data from https://www.justdial.com/Thrissur/Bus-On-Rent-For-Wedding-in-Kerala/nct-11275471. Status code: 403\n",
      "root - INFO - \n",
      "Scraping data from https://www.justdial.com/Ernakulam/Bus-On-Rent-For-Wedding/nct-11275471\n",
      "urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.justdial.com:443\n",
      "urllib3.connectionpool - DEBUG - https://www.justdial.com:443 \"GET /Ernakulam/Bus-On-Rent-For-Wedding/nct-11275471 HTTP/1.1\" 403 339\n",
      "root - WARNING - Error: Unable to fetch data from https://www.justdial.com/Ernakulam/Bus-On-Rent-For-Wedding/nct-11275471. Status code: 403\n",
      "root - INFO - \n",
      "Scraping data from https://www.redbus.in/bus-hire/wedding\n",
      "urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.redbus.in:443\n",
      "urllib3.connectionpool - DEBUG - https://www.redbus.in:443 \"GET /bus-hire/wedding HTTP/1.1\" 200 54750\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'bytes' object has no attribute 'page_content'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb Cell 20\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m time_f1 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m data \u001b[39m=\u001b[39m [scrape_data(url) \u001b[39mfor\u001b[39;00m url \u001b[39min\u001b[39;00m websites\u001b[39m.\u001b[39mvalues()]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mlen\u001b[39m(data)\n",
      "\u001b[1;32m/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb Cell 20\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m time_f1 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m data \u001b[39m=\u001b[39m [scrape_data(url) \u001b[39mfor\u001b[39;00m url \u001b[39min\u001b[39;00m websites\u001b[39m.\u001b[39mvalues()]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mlen\u001b[39m(data)\n",
      "\u001b[1;32m/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb Cell 20\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X23sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(url)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X23sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X23sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     \u001b[39m# soup = BeautifulSoup(response.text, \"html.parser\")\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X23sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X23sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X23sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m     \u001b[39m# data = remove_html_junk(data)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X23sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m     docs_transformed \u001b[39m=\u001b[39m bs_transformer\u001b[39m.\u001b[39mtransform_documents(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X23sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m     response, tags_to_extract\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39m<p>\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m<li>\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m<div>\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m<a>\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X23sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X23sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m     log\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSuccessfully scraped data from \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)   \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X23sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m docs_transformed\n",
      "File \u001b[0;32m~/miniconda3/envs/llm-env/lib/python3.11/site-packages/langchain/document_transformers/beautiful_soup_transformer.py:53\u001b[0m, in \u001b[0;36mBeautifulSoupTransformer.transform_documents\u001b[0;34m(self, documents, unwanted_tags, tags_to_extract, remove_lines, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39mTransform a list of Document objects by cleaning their HTML content.\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39m    A sequence of Document objects with transformed content.\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents:\n\u001b[0;32m---> 53\u001b[0m     cleaned_content \u001b[39m=\u001b[39m doc\u001b[39m.\u001b[39mpage_content\n\u001b[1;32m     55\u001b[0m     cleaned_content \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mremove_unwanted_tags(cleaned_content, unwanted_tags)\n\u001b[1;32m     57\u001b[0m     cleaned_content \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextract_tags(cleaned_content, tags_to_extract)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'bytes' object has no attribute 'page_content'"
     ]
    }
   ],
   "source": [
    "time_f1 = time.time()\n",
    "data = [scrape_data(url) for url in websites.values()]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the data to a file\n",
    "with open(\"data.txt\", \"w\") as f:\n",
    "    for item in data:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AsyncChromiumBrowser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import pprint\n",
    "import time\n",
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_transformers import (\n",
    "    beautiful_soup_transformer,\n",
    ")\n",
    "from langchain.document_loaders import AsyncChromiumLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.chains import create_extraction_chain\n",
    "\n",
    "loop = asyncio.get_event_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_with_playwright(urls):\n",
    "    t_flag1 = time.time()\n",
    "    loader = AsyncChromiumLoader(urls)\n",
    "    docs = loader.load()\n",
    "    t_flag2 = time.time()\n",
    "    print(\"AsyncChromiumLoader time: \", t_flag2 - t_flag1)\n",
    "\n",
    "    bs_transformer = beautiful_soup_transformer.BeautifulSoupTransformer()\n",
    "\n",
    "    docs_transformed = bs_transformer.transform_documents(\n",
    "        docs, tags_to_extract=[\"p\", \"li\", \"div\", \"a\", \"span\"]\n",
    "    )\n",
    "    t_flag3 = time.time()\n",
    "    print(\"BeautifulSoupTransformer time: \", t_flag3 - t_flag2)\n",
    "    print(\"Extracting content with LLM\")\n",
    "\n",
    "    # Grab the first 1000 tokens of the site\n",
    "    splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=800, chunk_overlap=50\n",
    "    )\n",
    "    t_flag4 = time.time()\n",
    "    print(\"RecursiveCharacterTextSplitter time: \", t_flag4 - t_flag3)\n",
    "    splits = splitter.split_documents(docs_transformed)\n",
    "\n",
    "    # extracted_content = extract(schema=schema, content=splits[0].page_content)\n",
    "    print(len(splits))\n",
    "    return splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb Cell 25\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m urls \u001b[39m=\u001b[39m [\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mhttps://keralatourbus.com/\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mhttps://www.justdial.com/Thrissur/Bus-On-Rent-For-Wedding-in-Kerala/nct-11275471\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X33sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mhttps://www.justdial.com/Ernakulam/Bus-On-Rent-For-Wedding/nct-11275471\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X33sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m ]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X33sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m extracted_content \u001b[39m=\u001b[39m scrape_with_playwright(urls)\n",
      "\u001b[1;32m/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb Cell 25\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m t_flag1 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m loader \u001b[39m=\u001b[39m AsyncChromiumLoader(urls)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X33sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m docs \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39mload()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X33sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m t_flag2 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X33sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAsyncChromiumLoader time: \u001b[39m\u001b[39m\"\u001b[39m, t_flag2 \u001b[39m-\u001b[39m t_flag1)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm-env/lib/python3.11/site-packages/langchain/document_loaders/chromium.py:90\u001b[0m, in \u001b[0;36mAsyncChromiumLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Document]:\n\u001b[1;32m     82\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[39m    Load and return all Documents from the provided URLs.\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     88\u001b[0m \n\u001b[1;32m     89\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlazy_load())\n",
      "File \u001b[0;32m~/miniconda3/envs/llm-env/lib/python3.11/site-packages/langchain/document_loaders/chromium.py:77\u001b[0m, in \u001b[0;36mAsyncChromiumLoader.lazy_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39mLazily load text content from the provided URLs.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     74\u001b[0m \n\u001b[1;32m     75\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[39mfor\u001b[39;00m url \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39murls:\n\u001b[0;32m---> 77\u001b[0m     html_content \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39mrun(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mascrape_playwright(url))\n\u001b[1;32m     78\u001b[0m     metadata \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39msource\u001b[39m\u001b[39m\"\u001b[39m: url}\n\u001b[1;32m     79\u001b[0m     \u001b[39myield\u001b[39;00m Document(page_content\u001b[39m=\u001b[39mhtml_content, metadata\u001b[39m=\u001b[39mmetadata)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm-env/lib/python3.11/asyncio/runners.py:186\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \n\u001b[1;32m    163\u001b[0m \u001b[39mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[39m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[39mif\u001b[39;00m events\u001b[39m.\u001b[39m_get_running_loop() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[39m# fail fast with short traceback\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    187\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    189\u001b[0m \u001b[39mwith\u001b[39;00m Runner(debug\u001b[39m=\u001b[39mdebug) \u001b[39mas\u001b[39;00m runner:\n\u001b[1;32m    190\u001b[0m     \u001b[39mreturn\u001b[39;00m runner\u001b[39m.\u001b[39mrun(main)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "urls = [\n",
    "    \"https://keralatourbus.com/\",\n",
    "    \"https://www.justdial.com/Thrissur/Bus-On-Rent-For-Wedding-in-Kerala/nct-11275471\",\n",
    "    \"https://www.sulekha.com/bus-rentals/trivandrum\",\n",
    "    \"https://www.shaadibaraati.com/wedding-transportation/kerala/oneness-travels/MGyvjmIxtV\",\n",
    "    \"https://devannmpd.wixsite.com/taxicarkerala/tourist-buses-in-cochin\",\n",
    "    \"https://www.asparkholidays.com/cochin/luxury-bus-hire\",\n",
    "    \"https://www.redbus.in/bus-hire/wedding\",\n",
    "    \"https://www.asparkholidays.com/thiruvananthapuram/book-volvo-bus\",\n",
    "    \"https://www.justdial.com/Ernakulam/Bus-On-Rent-For-Wedding/nct-11275471\",\n",
    "]\n",
    "extracted_content = scrape_with_playwright(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb Cell 26\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mawait\u001b[39;00m scrape_with_playwright(urls)\n",
      "\u001b[1;32m/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb Cell 26\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m t_flag1 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m loader \u001b[39m=\u001b[39m AsyncChromiumLoader(urls)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m docs \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39mload()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X34sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m t_flag2 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/anshuman/Anshu/Margati/PotentGPT/testings/potentgpt.ipynb#X34sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAsyncChromiumLoader time: \u001b[39m\u001b[39m\"\u001b[39m, t_flag2 \u001b[39m-\u001b[39m t_flag1)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm-env/lib/python3.11/site-packages/langchain/document_loaders/chromium.py:90\u001b[0m, in \u001b[0;36mAsyncChromiumLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Document]:\n\u001b[1;32m     82\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[39m    Load and return all Documents from the provided URLs.\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     88\u001b[0m \n\u001b[1;32m     89\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlazy_load())\n",
      "File \u001b[0;32m~/miniconda3/envs/llm-env/lib/python3.11/site-packages/langchain/document_loaders/chromium.py:77\u001b[0m, in \u001b[0;36mAsyncChromiumLoader.lazy_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39mLazily load text content from the provided URLs.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     74\u001b[0m \n\u001b[1;32m     75\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[39mfor\u001b[39;00m url \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39murls:\n\u001b[0;32m---> 77\u001b[0m     html_content \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39mrun(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mascrape_playwright(url))\n\u001b[1;32m     78\u001b[0m     metadata \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39msource\u001b[39m\u001b[39m\"\u001b[39m: url}\n\u001b[1;32m     79\u001b[0m     \u001b[39myield\u001b[39;00m Document(page_content\u001b[39m=\u001b[39mhtml_content, metadata\u001b[39m=\u001b[39mmetadata)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm-env/lib/python3.11/asyncio/runners.py:186\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \n\u001b[1;32m    163\u001b[0m \u001b[39mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[39m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[39mif\u001b[39;00m events\u001b[39m.\u001b[39m_get_running_loop() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[39m# fail fast with short traceback\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    187\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    189\u001b[0m \u001b[39mwith\u001b[39;00m Runner(debug\u001b[39m=\u001b[39mdebug) \u001b[39mas\u001b[39;00m runner:\n\u001b[1;32m    190\u001b[0m     \u001b[39mreturn\u001b[39;00m runner\u001b[39m.\u001b[39mrun(main)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "await scrape_with_playwright(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
