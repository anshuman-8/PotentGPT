{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import logging as log\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal = \"I need few developers for my new startup, I am looking for people with 2 years of experience in python and react.\"\n",
    "location = \"Bengaluru, Karnataka, India\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://keralatourbus.com/\",\n",
    "    \"https://www.justdial.com/Thrissur/Bus-On-Rent-For-Wedding-in-Kerala/nct-11275471\",\n",
    "    \"https://www.sulekha.com/bus-rentals/trivandrum\",\n",
    "    \"https://www.shaadibaraati.com/wedding-transportation/kerala/oneness-travels/MGyvjmIxtV\",\n",
    "    \"https://devannmpd.wixsite.com/taxicarkerala/tourist-buses-in-cochin\",\n",
    "    \"https://www.asparkholidays.com/cochin/luxury-bus-hire\",\n",
    "    \"https://www.redbus.in/bus-hire/wedding\",\n",
    "    \"https://www.asparkholidays.com/thiruvananthapuram/book-volvo-bus\",\n",
    "    \"https://www.justdial.com/Ernakulam/Bus-On-Rent-For-Wedding/nct-11275471\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_junk(data):\n",
    "    # remove all class names\n",
    "    data = re.sub(r'(?is)class=\"[^\"]*\"', '', data)\n",
    "    data = re.sub(r'(?is)className=\"[^\"]*\"', '', data)\n",
    "\n",
    "    # remove all inline styles\n",
    "    data = re.sub(r'(?is)style=\"[^\"]*\"', '', data)\n",
    "\n",
    "    # remove all aria-label\n",
    "    data = re.sub(r'(?is)aria-label=\"[^\"]*\"', '', data)\n",
    "\n",
    "    # remove all comments\n",
    "    data = re.sub(r'(?s)<!--(.*?)-->[\\n]?', '', data)\n",
    "\n",
    "    # remove all ids\n",
    "    data = re.sub(r'(?is)id=\"[^\"]*\"', '', data)\n",
    "\n",
    "    # remove all newlines, long space and tabs\n",
    "    data = re.sub(r'[\\n\\t]', ' ', data)\n",
    "    data = re.sub(r' +', ' ', data)\n",
    "\n",
    "    # remove all non-imp tags both open and close\n",
    "    remove_tags = [\"span\", \"div\", \"strong\", \"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\", \"b\", \"li\", \"p\", \"ui\", \"section\"]   \n",
    "    for tag in remove_tags:\n",
    "        data = re.sub(r'(?is)<{}[^>]*>'.format(tag), '', data)\n",
    "        data = re.sub(r'(?is)</{}[^>]*>'.format(tag), '', data) \n",
    "\n",
    "    return data\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import html2text\n",
    "\n",
    "h = html2text.HTML2Text()\n",
    "\n",
    "def scrape_data(url):\n",
    "    log.info(f\"\\nScraping data from {url}\")\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        \n",
    "        unwanted_tags = [\n",
    "            \"pre\",\n",
    "            \"code\",\n",
    "            \"blockquote\",\n",
    "            \"em\",\n",
    "            \"br\",\n",
    "            \"source\",\n",
    "            \"circle\",\n",
    "            \"svg\",\n",
    "            \"img\",\n",
    "            \"button\",\n",
    "            \"input\",\n",
    "            \"form\",\n",
    "            \"footer\",\n",
    "            \"header\",\n",
    "            \"aside\",\n",
    "            \"nav\",\n",
    "            \"script\",\n",
    "            \"style\",\n",
    "            \"noscript\",\n",
    "            \"iframe\",\n",
    "            \"meta\",\n",
    "            \"head\",\n",
    "            \n",
    "        ]\n",
    "        for tag in unwanted_tags:\n",
    "            for match in soup.find_all(tag):\n",
    "                match.decompose()\n",
    "        if soup.body is None:\n",
    "            log.warning(f\"Error: Unable to fetch data from {url}\")\n",
    "            return \"\"\n",
    "        try:\n",
    "            # data = soup.body.prettify()\n",
    "            data = soup.main.prettify()\n",
    "        except:\n",
    "            data = soup.body.prettify()\n",
    "\n",
    "        data = remove_html_junk(data)\n",
    "\n",
    "    \n",
    "        log.info(f\"Successfully scraped data from {url}\")   \n",
    "        return data\n",
    "\n",
    "    else:\n",
    "        log.warning(\n",
    "            f\"Error: Unable to fetch data from {url}. Status code: {response.status_code}\"\n",
    "        )\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ansuhman@mu.com', 'sdf09usdf@mail.co']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "email_list = [\"ansuhman@mu.com\", \"kahara\", \"somethis sdf09usdf@mail.co\"]\n",
    "email_list2 = [\"ansuhman@mu.com kahara somethis sdf09usdf@mail.co\"]\n",
    "\n",
    "# if isinstance(email_list2, list):\n",
    "emails = re.findall(\n",
    "    r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b\",\n",
    "    \", \".join(email_list2), \n",
    ")\n",
    "\n",
    "emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for results, source in zip([google_search, bing_search], [\"Google\", \"Bing\"]):\n",
    "            for result in results:\n",
    "                search_link = result[\"link\"]\n",
    "\n",
    "                if search_link in search_index:\n",
    "                    if source not in search_index[search_link][\"source\"]:\n",
    "                        search_index[search_link][\"source\"].append(source)\n",
    "                else:\n",
    "                    search_index[search_link] = {\n",
    "                        \"title\": result[\"title\"],\n",
    "                        \"link\": result[\"link\"],\n",
    "                        \"query\": result[\"query\"],\n",
    "                        \"source\": [source],\n",
    "                    }\n",
    "\n",
    "        final_result = list(search_index.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A D\n",
      "B E\n",
      "C F\n"
     ]
    }
   ],
   "source": [
    "# dummy data\n",
    "google_search = [\n",
    "    \"A\", \"B\", \"C\"\n",
    "]\n",
    "\n",
    "bing_search = [\n",
    "\"D\", \"E\", \"F\"\n",
    "]\n",
    "\n",
    "for a,b in zip(google_search, bing_search):\n",
    "    # print(results[0], results[1])\n",
    "    print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'A',\n",
       "  'link': 'https://www.google.com',\n",
       "  'query': 'python',\n",
       "  'source': ['Google']},\n",
       " {'title': 'D',\n",
       "  'link': 'https://www.bing.com',\n",
       "  'query': 'python',\n",
       "  'source': ['Bing']}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# dummy data\n",
    "google_search = [\n",
    "    {\n",
    "        \"title\": \"A\",\n",
    "        \"link\": \"https://www.google.com\",\n",
    "        \"query\": \"python\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"B\",\n",
    "        \"link\": \"https://www.google.com\",\n",
    "        \"query\": \"python\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"C\",\n",
    "        \"link\": \"https://www.google.com\",\n",
    "        \"query\": \"python\"\n",
    "    }\n",
    "]\n",
    "\n",
    "bing_search = [\n",
    "    {\n",
    "        \"title\": \"D\",\n",
    "        \"link\": \"https://www.bing.com\",\n",
    "        \"query\": \"python\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"E\",\n",
    "        \"link\": \"https://www.bing.com\",\n",
    "        \"query\": \"python\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"F\",\n",
    "        \"link\": \"https://www.bing.com\",\n",
    "        \"query\": \"python\"\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "search_index = {}\n",
    "\n",
    "for results in zip(google_search, bing_search):\n",
    "            for i in range(2):\n",
    "                source = \"Google\" if i == 0 else \"Bing\"\n",
    "                search_link = results[i][\"link\"]\n",
    "\n",
    "                if search_link in search_index:\n",
    "                    if source not in search_index[search_link][\"source\"]:\n",
    "                        search_index[search_link][\"source\"].append(source)\n",
    "                else:\n",
    "                    search_index[search_link] = {\n",
    "                        \"title\": results[i][\"title\"],\n",
    "                        \"link\": results[i][\"link\"],\n",
    "                        \"query\": results[i][\"query\"],\n",
    "                        \"source\": [source],\n",
    "                    }\n",
    "\n",
    "final_result = list(search_index.values())\n",
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
